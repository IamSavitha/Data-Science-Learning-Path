{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Complete Guide\n",
    "\n",
    "## From Theory to Implementation with Visualizations\n",
    "\n",
    "Logistic Regression is one of the most fundamental algorithms for **binary classification**. Despite its name, it's a classification algorithm, not regression.\n",
    "\n",
    "### What You'll Learn\n",
    "1. Mathematical foundations (sigmoid, log-odds)\n",
    "2. Cost function and gradient descent\n",
    "3. Implementation from scratch\n",
    "4. Scikit-learn implementation\n",
    "5. Multiclass classification\n",
    "6. Regularization (L1, L2)\n",
    "7. Model evaluation and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, auc, precision_recall_curve)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Sigmoid Function\n",
    "\n",
    "The sigmoid function maps any real number to a value between 0 and 1:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "This is crucial for converting linear predictions to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Visualize sigmoid function\n",
    "z = np.linspace(-10, 10, 200)\n",
    "sig = sigmoid(z)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sigmoid curve\n",
    "axes[0].plot(z, sig, 'b-', linewidth=2)\n",
    "axes[0].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='Decision boundary (0.5)')\n",
    "axes[0].axvline(x=0, color='g', linestyle='--', alpha=0.7)\n",
    "axes[0].fill_between(z, 0, sig, where=(z > 0), alpha=0.3, color='green', label='Class 1')\n",
    "axes[0].fill_between(z, 0, sig, where=(z <= 0), alpha=0.3, color='red', label='Class 0')\n",
    "axes[0].set_xlabel('z (linear combination)', fontsize=12)\n",
    "axes[0].set_ylabel('σ(z) = P(y=1|x)', fontsize=12)\n",
    "axes[0].set_title('Sigmoid Function', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Derivative of sigmoid\n",
    "sig_derivative = sig * (1 - sig)\n",
    "axes[1].plot(z, sig_derivative, 'purple', linewidth=2)\n",
    "axes[1].set_xlabel('z', fontsize=12)\n",
    "axes[1].set_ylabel(\"σ'(z)\", fontsize=12)\n",
    "axes[1].set_title('Derivative of Sigmoid: σ(z)(1-σ(z))', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key properties of sigmoid:\")\n",
    "print(f\"σ(0) = {sigmoid(0):.3f}\")\n",
    "print(f\"σ(large +ve) → {sigmoid(10):.6f}\")\n",
    "print(f\"σ(large -ve) → {sigmoid(-10):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression Model\n",
    "\n",
    "The model predicts the probability of class 1:\n",
    "\n",
    "$$P(y=1|\\mathbf{x}) = \\sigma(\\mathbf{w}^T\\mathbf{x} + b) = \\frac{1}{1 + e^{-(\\mathbf{w}^T\\mathbf{x} + b)}}$$\n",
    "\n",
    "### Log-Odds (Logit) Interpretation\n",
    "\n",
    "$$\\log\\left(\\frac{P(y=1)}{P(y=0)}\\right) = \\mathbf{w}^T\\mathbf{x} + b$$\n",
    "\n",
    "The linear combination represents the **log-odds** of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate binary classification data\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_redundant=0,\n",
    "                           n_informative=2, n_clusters_per_class=1,\n",
    "                           class_sep=1.5, random_state=42)\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', edgecolors='black', s=100)\n",
    "plt.colorbar(scatter, label='Class')\n",
    "plt.xlabel('Feature 1', fontsize=12)\n",
    "plt.ylabel('Feature 2', fontsize=12)\n",
    "plt.title('Binary Classification Dataset', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cost Function: Binary Cross-Entropy\n",
    "\n",
    "We cannot use MSE for classification (non-convex). Instead, we use **log loss**:\n",
    "\n",
    "$$J(\\mathbf{w}, b) = -\\frac{1}{m}\\sum_{i=1}^{m}\\left[y^{(i)}\\log(\\hat{y}^{(i)}) + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})\\right]$$\n",
    "\n",
    "This penalizes confident wrong predictions heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cost function behavior\n",
    "p = np.linspace(0.001, 0.999, 100)\n",
    "\n",
    "# Cost when y=1: -log(p)\n",
    "cost_y1 = -np.log(p)\n",
    "# Cost when y=0: -log(1-p)\n",
    "cost_y0 = -np.log(1 - p)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(p, cost_y1, 'b-', linewidth=2, label='y=1: -log(p)')\n",
    "axes[0].set_xlabel('Predicted Probability p', fontsize=12)\n",
    "axes[0].set_ylabel('Cost', fontsize=12)\n",
    "axes[0].set_title('Cost when Actual Class = 1', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].annotate('Low cost when p→1', xy=(0.9, 0.1), fontsize=10)\n",
    "axes[0].annotate('High cost when p→0', xy=(0.1, 2), fontsize=10)\n",
    "\n",
    "axes[1].plot(p, cost_y0, 'r-', linewidth=2, label='y=0: -log(1-p)')\n",
    "axes[1].set_xlabel('Predicted Probability p', fontsize=12)\n",
    "axes[1].set_ylabel('Cost', fontsize=12)\n",
    "axes[1].set_title('Cost when Actual Class = 0', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].annotate('Low cost when p→0', xy=(0.1, 0.1), fontsize=10)\n",
    "axes[1].annotate('High cost when p→1', xy=(0.8, 2), fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    \"\"\"Logistic Regression implementation from scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the model using gradient descent\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.n_iterations):\n",
    "            # Forward pass\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_pred)\n",
    "            \n",
    "            # Compute cost\n",
    "            cost = (-1/n_samples) * np.sum(\n",
    "                y * np.log(predictions + 1e-15) + \n",
    "                (1 - y) * np.log(1 - predictions + 1e-15)\n",
    "            )\n",
    "            self.cost_history.append(cost)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities\"\"\"\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        return sigmoid(linear_pred)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "# Train the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train our model\n",
    "model_scratch = LogisticRegressionScratch(learning_rate=0.1, n_iterations=1000)\n",
    "model_scratch.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model_scratch.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy (from scratch): {accuracy:.4f}\")\n",
    "print(f\"Weights: {model_scratch.weights}\")\n",
    "print(f\"Bias: {model_scratch.bias:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress and decision boundary\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cost history\n",
    "axes[0].plot(model_scratch.cost_history, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('Iteration', fontsize=12)\n",
    "axes[0].set_ylabel('Cost', fontsize=12)\n",
    "axes[0].set_title('Training Progress: Cost vs Iterations', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_train_scaled[:, 0].min() - 1, X_train_scaled[:, 0].max() + 1\n",
    "y_min, y_max = X_train_scaled[:, 1].min() - 1, X_train_scaled[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = model_scratch.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "axes[1].contourf(xx, yy, Z, levels=50, cmap='RdYlBu', alpha=0.8)\n",
    "axes[1].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c=y_train, \n",
    "                cmap='RdYlBu', edgecolors='black', s=100)\n",
    "axes[1].contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "axes[1].set_xlabel('Feature 1 (scaled)', fontsize=12)\n",
    "axes[1].set_ylabel('Feature 2 (scaled)', fontsize=12)\n",
    "axes[1].set_title('Decision Boundary with Probability Contours', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scikit-learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn's LogisticRegression\n",
    "model_sklearn = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_sklearn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_sklearn = model_sklearn.predict(X_test_scaled)\n",
    "y_prob_sklearn = model_sklearn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"Accuracy (sklearn): {accuracy_score(y_test, y_pred_sklearn):.4f}\")\n",
    "print(f\"\\nCoefficients: {model_sklearn.coef_[0]}\")\n",
    "print(f\"Intercept: {model_sklearn.intercept_[0]:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation: ROC Curve and Precision-Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve and Precision-Recall Curve\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_sklearn)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_prob_sklearn)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random Classifier')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.3)\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14)\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_prob_sklearn)\n",
    "\n",
    "axes[2].plot(recall, precision, 'g-', linewidth=2)\n",
    "axes[2].fill_between(recall, precision, alpha=0.3, color='green')\n",
    "axes[2].set_xlabel('Recall', fontsize=12)\n",
    "axes[2].set_ylabel('Precision', fontsize=12)\n",
    "axes[2].set_title('Precision-Recall Curve', fontsize=14)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiclass Classification\n",
    "\n",
    "Logistic Regression can be extended to multiple classes using:\n",
    "- **One-vs-Rest (OvR)**: Train K binary classifiers\n",
    "- **Multinomial (Softmax)**: Direct multiclass probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset (3 classes)\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "feature_names = iris.feature_names\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split and scale\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_iris = StandardScaler()\n",
    "X_train_iris_scaled = scaler_iris.fit_transform(X_train_iris)\n",
    "X_test_iris_scaled = scaler_iris.transform(X_test_iris)\n",
    "\n",
    "# Train multinomial logistic regression\n",
    "model_multi = LogisticRegression(multi_class='multinomial', max_iter=1000, random_state=42)\n",
    "model_multi.fit(X_train_iris_scaled, y_train_iris)\n",
    "\n",
    "# Predictions\n",
    "y_pred_iris = model_multi.predict(X_test_iris_scaled)\n",
    "y_prob_iris = model_multi.predict_proba(X_test_iris_scaled)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test_iris, y_pred_iris):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_iris, y_pred_iris, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiclass results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_iris = confusion_matrix(y_test_iris, y_pred_iris)\n",
    "sns.heatmap(cm_iris, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('Actual', fontsize=12)\n",
    "axes[0].set_title('Multiclass Confusion Matrix', fontsize=14)\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "coef_df = pd.DataFrame(model_multi.coef_, columns=feature_names, index=class_names)\n",
    "coef_df.T.plot(kind='bar', ax=axes[1], colormap='viridis')\n",
    "axes[1].set_xlabel('Features', fontsize=12)\n",
    "axes[1].set_ylabel('Coefficient Value', fontsize=12)\n",
    "axes[1].set_title('Feature Coefficients by Class', fontsize=14)\n",
    "axes[1].legend(title='Class')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Regularization: L1 (Lasso) and L2 (Ridge)\n",
    "\n",
    "Regularization prevents overfitting by adding penalty to the cost function:\n",
    "\n",
    "- **L2 (Ridge)**: $J(\\mathbf{w}) + \\lambda\\sum w_j^2$ → shrinks coefficients\n",
    "- **L1 (Lasso)**: $J(\\mathbf{w}) + \\lambda\\sum |w_j|$ → sparse coefficients (feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load breast cancer dataset (high-dimensional)\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer.data, cancer.target\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_c = StandardScaler()\n",
    "X_train_c_scaled = scaler_c.fit_transform(X_train_c)\n",
    "X_test_c_scaled = scaler_c.transform(X_test_c)\n",
    "\n",
    "# Compare different regularization strengths\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]  # C = 1/λ\n",
    "\n",
    "results = {'C': [], 'L1_train': [], 'L1_test': [], 'L2_train': [], 'L2_test': [],\n",
    "           'L1_nonzero': [], 'L2_nonzero': []}\n",
    "\n",
    "for C in C_values:\n",
    "    # L1 regularization\n",
    "    model_l1 = LogisticRegression(penalty='l1', C=C, solver='saga', max_iter=5000)\n",
    "    model_l1.fit(X_train_c_scaled, y_train_c)\n",
    "    \n",
    "    # L2 regularization\n",
    "    model_l2 = LogisticRegression(penalty='l2', C=C, max_iter=5000)\n",
    "    model_l2.fit(X_train_c_scaled, y_train_c)\n",
    "    \n",
    "    results['C'].append(C)\n",
    "    results['L1_train'].append(model_l1.score(X_train_c_scaled, y_train_c))\n",
    "    results['L1_test'].append(model_l1.score(X_test_c_scaled, y_test_c))\n",
    "    results['L2_train'].append(model_l2.score(X_train_c_scaled, y_train_c))\n",
    "    results['L2_test'].append(model_l2.score(X_test_c_scaled, y_test_c))\n",
    "    results['L1_nonzero'].append(np.sum(model_l1.coef_ != 0))\n",
    "    results['L2_nonzero'].append(np.sum(model_l2.coef_ != 0))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regularization effects\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy vs C\n",
    "axes[0].semilogx(results['C'], results['L1_test'], 'b-o', label='L1 Test', linewidth=2)\n",
    "axes[0].semilogx(results['C'], results['L2_test'], 'r-s', label='L2 Test', linewidth=2)\n",
    "axes[0].semilogx(results['C'], results['L1_train'], 'b--', alpha=0.5, label='L1 Train')\n",
    "axes[0].semilogx(results['C'], results['L2_train'], 'r--', alpha=0.5, label='L2 Train')\n",
    "axes[0].set_xlabel('C (Inverse Regularization Strength)', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Regularization Effect on Accuracy', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Number of non-zero coefficients\n",
    "axes[1].semilogx(results['C'], results['L1_nonzero'], 'b-o', label='L1', linewidth=2)\n",
    "axes[1].semilogx(results['C'], results['L2_nonzero'], 'r-s', label='L2', linewidth=2)\n",
    "axes[1].axhline(y=30, color='gray', linestyle='--', label='Total features')\n",
    "axes[1].set_xlabel('C (Inverse Regularization Strength)', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Non-Zero Coefficients', fontsize=12)\n",
    "axes[1].set_title('Feature Sparsity: L1 vs L2', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance and Interpretation\n",
    "\n",
    "Coefficients in logistic regression have a clear interpretation:\n",
    "- **Sign**: Direction of effect on probability\n",
    "- **Magnitude**: Strength of effect\n",
    "- **Exp(coef)**: Odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with optimal C\n",
    "best_model = LogisticRegression(penalty='l2', C=1.0, max_iter=5000)\n",
    "best_model.fit(X_train_c_scaled, y_train_c)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': cancer.feature_names,\n",
    "    'Coefficient': best_model.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(best_model.coef_[0]),\n",
    "    'Odds_Ratio': np.exp(best_model.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "top_features = feature_importance.head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in top_features['Coefficient']]\n",
    "plt.barh(top_features['Feature'], top_features['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 15 Feature Coefficients\\n(Green = increases malignant probability, Red = decreases)', fontsize=14)\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Threshold Tuning\n",
    "\n",
    "The default threshold is 0.5, but you can adjust it based on the cost of false positives vs false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze different thresholds\n",
    "y_prob_cancer = best_model.predict_proba(X_test_c_scaled)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "metrics = {'threshold': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob_cancer >= thresh).astype(int)\n",
    "    \n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    \n",
    "    metrics['threshold'].append(thresh)\n",
    "    metrics['accuracy'].append(accuracy_score(y_test_c, y_pred_thresh))\n",
    "    metrics['precision'].append(precision_score(y_test_c, y_pred_thresh))\n",
    "    metrics['recall'].append(recall_score(y_test_c, y_pred_thresh))\n",
    "    metrics['f1'].append(f1_score(y_test_c, y_pred_thresh))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(metrics['threshold'], metrics['accuracy'], 'b-o', label='Accuracy', linewidth=2)\n",
    "plt.plot(metrics['threshold'], metrics['precision'], 'g-s', label='Precision', linewidth=2)\n",
    "plt.plot(metrics['threshold'], metrics['recall'], 'r-^', label='Recall', linewidth=2)\n",
    "plt.plot(metrics['threshold'], metrics['f1'], 'purple', marker='d', label='F1 Score', linewidth=2)\n",
    "plt.axvline(x=0.5, color='gray', linestyle='--', label='Default threshold')\n",
    "plt.xlabel('Classification Threshold', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Metrics vs Classification Threshold', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Logistic Regression** uses the sigmoid function to model probabilities\n",
    "2. **Binary Cross-Entropy** is the appropriate loss function\n",
    "3. **Gradient Descent** optimizes the parameters\n",
    "4. **Regularization** (L1/L2) prevents overfitting and enables feature selection\n",
    "5. **Multiclass** extension uses softmax (multinomial) or OvR\n",
    "6. **Interpretation**: Coefficients represent log-odds changes\n",
    "\n",
    "### When to Use Logistic Regression\n",
    "\n",
    "**Use when:**\n",
    "- You need a fast, interpretable model\n",
    "- Features are roughly linearly separable\n",
    "- You need probability outputs\n",
    "- Feature importance is needed\n",
    "\n",
    "**Avoid when:**\n",
    "- Complex non-linear relationships exist\n",
    "- Very high-dimensional sparse data (use specialized methods)\n",
    "\n",
    "### Practice Problems\n",
    "\n",
    "1. Implement mini-batch gradient descent for logistic regression\n",
    "2. Add L2 regularization to the scratch implementation\n",
    "3. Compare OvR vs Multinomial on a 5-class problem\n",
    "4. Find the optimal threshold for a medical diagnosis problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
