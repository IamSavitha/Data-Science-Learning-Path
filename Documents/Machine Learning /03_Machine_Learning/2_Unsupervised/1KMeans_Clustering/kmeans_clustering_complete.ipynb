{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering - Complete Guide\n",
    "\n",
    "## From Theory to Implementation\n",
    "\n",
    "K-Means is one of the most popular **unsupervised learning algorithms** for clustering. It groups similar data points together by finding cluster centers (centroids).\n",
    "\n",
    "### What You'll Learn\n",
    "1. What clustering is and when to use K-Means\n",
    "2. K-Means algorithm step-by-step\n",
    "3. Choosing the optimal number of clusters (K)\n",
    "4. Implementation from scratch\n",
    "5. Scikit-learn implementation\n",
    "6. Initialization strategies (K-means++)\n",
    "7. Limitations and alternatives\n",
    "8. Real-world applications\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs, make_moons, load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"K-Means Clustering Complete Guide\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Clustering?\n",
    "\n",
    "### Clustering Definition\n",
    "\n",
    "**Clustering** is an unsupervised learning technique that groups similar data points together **without labeled training data**.\n",
    "\n",
    "### Why Clustering?\n",
    "\n",
    "- ✅ **Customer Segmentation**: Group customers by behavior\n",
    "- ✅ **Image Segmentation**: Separate objects in images  \n",
    "- ✅ **Anomaly Detection**: Identify outliers\n",
    "- ✅ **Data Exploration**: Discover hidden patterns\n",
    "- ✅ **Preprocessing**: Group similar features\n",
    "\n",
    "### Types of Clustering\n",
    "\n",
    "1. **Centroid-based** (K-Means, K-Medoids)\n",
    "2. **Hierarchical** (Agglomerative, Divisive)\n",
    "3. **Density-based** (DBSCAN)\n",
    "4. **Distribution-based** (Gaussian Mixture Models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering concept\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Before clustering\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c='gray', alpha=0.6, s=50)\n",
    "plt.title('Before Clustering\\n(Unlabeled Data)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# After clustering (ground truth for demonstration)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.title('True Clusters\\n(Ground Truth)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# After K-Means clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', \n",
    "            s=200, linewidths=3, label='Centroids')\n",
    "plt.title('K-Means Clustering\\n(4 Clusters)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Goal: Find {kmeans.n_clusters} clusters (groups) in unlabeled data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Algorithm\n",
    "\n",
    "### Algorithm Steps\n",
    "\n",
    "**K-Means** partitions data into K clusters by:\n",
    "\n",
    "1. **Initialize**: Choose K random points as initial centroids\n",
    "2. **Assign**: Assign each data point to nearest centroid\n",
    "3. **Update**: Recalculate centroids as mean of assigned points\n",
    "4. **Repeat**: Steps 2-3 until convergence (centroids don't change)\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "**Objective Function** (Within-Cluster Sum of Squares - WCSS):\n",
    "\n",
    "$$J = \\sum_{i=1}^{K} \\sum_{x \\in C_i} ||x - \\mu_i||^2$$\n",
    "\n",
    "Where:\n",
    "- $K$ = number of clusters\n",
    "- $C_i$ = set of points in cluster $i$\n",
    "- $\\mu_i$ = centroid of cluster $i$\n",
    "- $||x - \\mu_i||^2$ = squared distance from point to centroid\n",
    "\n",
    "**Goal**: Minimize $J$ (minimize distances within clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Means steps\n",
    "def visualize_kmeans_steps(X, k=3, max_iter=3):\n",
    "    \"\"\"Visualize K-Means algorithm steps\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Initialize random centroids\n",
    "    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, max_iter+1, figsize=(16, 4))\n",
    "    \n",
    "    for iteration in range(max_iter + 1):\n",
    "        # Assign points to nearest centroid\n",
    "        distances = cdist(X, centroids)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[iteration]\n",
    "        for i in range(k):\n",
    "            cluster_points = X[labels == i]\n",
    "            ax.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                      alpha=0.6, s=50, label=f'Cluster {i+1}')\n",
    "        \n",
    "        ax.scatter(centroids[:, 0], centroids[:, 1], \n",
    "                  c='red', marker='x', s=200, linewidths=3, \n",
    "                  label='Centroids')\n",
    "        \n",
    "        ax.set_title(f'Iteration {iteration}\\n(Centroid Update)', fontweight='bold')\n",
    "        ax.set_xlabel('Feature 1')\n",
    "        ax.set_ylabel('Feature 2')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Update centroids\n",
    "        if iteration < max_iter:\n",
    "            new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n",
    "            \n",
    "            # Draw lines showing centroid movement\n",
    "            for i in range(k):\n",
    "                ax.plot([centroids[i, 0], new_centroids[i, 0]], \n",
    "                       [centroids[i, 1], new_centroids[i, 1]], \n",
    "                       'r--', alpha=0.5, linewidth=2)\n",
    "            \n",
    "            centroids = new_centroids\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate sample data\n",
    "X_sample, _ = make_blobs(n_samples=150, centers=3, cluster_std=1.0, random_state=42)\n",
    "\n",
    "print(\"K-Means Algorithm Visualization:\")\n",
    "print(\"Watch how centroids move and clusters form!\")\n",
    "visualize_kmeans_steps(X_sample, k=3, max_iter=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansScratch:\n",
    "    \"\"\"K-Means Clustering from Scratch\"\"\"\n",
    "    \n",
    "    def __init__(self, n_clusters=3, max_iters=100, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iters = max_iters\n",
    "        self.random_state = random_state\n",
    "        self.centroids = None\n",
    "        self.labels_ = None\n",
    "        self.inertia_ = None  # WCSS\n",
    "    \n",
    "    def _initialize_centroids(self, X):\n",
    "        \"\"\"Initialize centroids randomly\"\"\"\n",
    "        if self.random_state:\n",
    "            np.random.seed(self.random_state)\n",
    "        indices = np.random.choice(X.shape[0], self.n_clusters, replace=False)\n",
    "        return X[indices].copy()\n",
    "    \n",
    "    def _assign_clusters(self, X, centroids):\n",
    "        \"\"\"Assign each point to nearest centroid\"\"\"\n",
    "        distances = cdist(X, centroids)\n",
    "        return np.argmin(distances, axis=1)\n",
    "    \n",
    "    def _update_centroids(self, X, labels):\n",
    "        \"\"\"Update centroids as mean of assigned points\"\"\"\n",
    "        new_centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_points = X[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                new_centroids[i] = cluster_points.mean(axis=0)\n",
    "            else:\n",
    "                # Handle empty cluster\n",
    "                new_centroids[i] = X[np.random.choice(X.shape[0])]\n",
    "        return new_centroids\n",
    "    \n",
    "    def _calculate_inertia(self, X, labels, centroids):\n",
    "        \"\"\"Calculate within-cluster sum of squares (WCSS)\"\"\"\n",
    "        inertia = 0\n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_points = X[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                inertia += np.sum((cluster_points - centroids[i])**2)\n",
    "        return inertia\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit K-Means to data\"\"\"\n",
    "        # Initialize centroids\n",
    "        self.centroids = self._initialize_centroids(X)\n",
    "        \n",
    "        for iteration in range(self.max_iters):\n",
    "            # Assign points to clusters\n",
    "            labels = self._assign_clusters(X, self.centroids)\n",
    "            \n",
    "            # Update centroids\n",
    "            new_centroids = self._update_centroids(X, labels)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.allclose(self.centroids, new_centroids):\n",
    "                print(f\"Converged after {iteration + 1} iterations\")\n",
    "                break\n",
    "            \n",
    "            self.centroids = new_centroids\n",
    "        \n",
    "        # Final assignment\n",
    "        self.labels_ = self._assign_clusters(X, self.centroids)\n",
    "        self.inertia_ = self._calculate_inertia(X, self.labels_, self.centroids)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict cluster for new points\"\"\"\n",
    "        if self.centroids is None:\n",
    "            raise ValueError(\"Model must be fitted first\")\n",
    "        return self._assign_clusters(X, self.centroids)\n",
    "\n",
    "# Test our implementation\n",
    "X_test, y_true = make_blobs(n_samples=200, centers=3, cluster_std=1.0, random_state=42)\n",
    "\n",
    "kmeans_scratch = KMeansScratch(n_clusters=3, max_iters=100, random_state=42)\n",
    "kmeans_scratch.fit(X_test)\n",
    "\n",
    "print(f\"\\nNumber of clusters: {kmeans_scratch.n_clusters}\")\n",
    "print(f\"Inertia (WCSS): {kmeans_scratch.inertia_:.2f}\")\n",
    "print(f\"Centroids:\\n{kmeans_scratch.centroids}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_true, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.title('True Clusters', fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=kmeans_scratch.labels_, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(kmeans_scratch.centroids[:, 0], kmeans_scratch.centroids[:, 1], \n",
    "           c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "plt.title('K-Means Clustering (From Scratch)', fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method and Silhouette Score\n",
    "X_elbow, _ = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)\n",
    "\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_elbow)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_elbow, kmeans.labels_))\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=4, color='r', linestyle='--', alpha=0.7, label='Optimal K=4')\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (WCSS)', fontsize=12)\n",
    "plt.title('Elbow Method\\n(Look for the \"Elbow\")', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Plot Silhouette Score\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(K_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "plt.axvline(x=optimal_k, color='r', linestyle='--', alpha=0.7, \n",
    "            label=f'Optimal K={optimal_k}')\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Silhouette Score', fontsize=12)\n",
    "plt.title('Silhouette Score Method\\n(Higher is Better)', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Compare different K values visually\n",
    "plt.subplot(1, 3, 3)\n",
    "kmeans_best = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "y_best = kmeans_best.fit_predict(X_elbow)\n",
    "plt.scatter(X_elbow[:, 0], X_elbow[:, 1], c=y_best, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(kmeans_best.cluster_centers_[:, 0], kmeans_best.cluster_centers_[:, 1],\n",
    "           c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "plt.title(f'K={4} Clusters\\n(Optimal)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal K (Elbow method): 4\")\n",
    "print(f\"Optimal K (Silhouette): {optimal_k} (score: {max(silhouette_scores):.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Scale features (important for K-Means!)\n",
    "scaler = StandardScaler()\n",
    "X_iris_scaled = scaler.fit_transform(X_iris)\n",
    "\n",
    "# Apply K-Means\n",
    "kmeans_iris = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "y_pred_iris = kmeans_iris.fit_predict(X_iris_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Iris Dataset Clustering Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of clusters: {kmeans_iris.n_clusters}\")\n",
    "print(f\"Inertia: {kmeans_iris.inertia_:.2f}\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X_iris_scaled, y_pred_iris):.3f}\")\n",
    "print(f\"\\nCluster sizes: {np.bincount(y_pred_iris)}\")\n",
    "\n",
    "# Visualize (using first 2 features)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.title('True Labels (Species)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_iris[:, 0], X_iris[:, 1], c=y_pred_iris, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(scaler.inverse_transform(kmeans_iris.cluster_centers_)[:, 0], \n",
    "           scaler.inverse_transform(kmeans_iris.cluster_centers_)[:, 1],\n",
    "           c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.title('K-Means Clustering (K=3)', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: K-Means found 3 clusters (matching 3 iris species!)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples where K-Means struggles\n",
    "\n",
    "# 1. Non-spherical clusters (moons)\n",
    "X_moons, y_moons = make_moons(n_samples=200, noise=0.1, random_state=42)\n",
    "kmeans_moons = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "y_pred_moons = kmeans_moons.fit_predict(X_moons)\n",
    "\n",
    "# 2. Different sized clusters\n",
    "X_unequal, _ = make_blobs(n_samples=[50, 200, 50], centers=3, cluster_std=[1.5, 0.5, 1.5], random_state=42)\n",
    "kmeans_unequal = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "y_pred_unequal = kmeans_unequal.fit_predict(X_unequal)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Moons\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_pred_moons, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(kmeans_moons.cluster_centers_[:, 0], kmeans_moons.cluster_centers_[:, 1],\n",
    "           c='red', marker='x', s=200, linewidths=3)\n",
    "plt.title('K-Means on Non-Spherical Data\\n(Doesn\\'t work well!)', fontweight='bold', color='red')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Unequal sizes\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_unequal[:, 0], X_unequal[:, 1], c=y_pred_unequal, cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(kmeans_unequal.cluster_centers_[:, 0], kmeans_unequal.cluster_centers_[:, 1],\n",
    "           c='red', marker='x', s=200, linewidths=3)\n",
    "plt.title('K-Means on Unequal Sized Clusters\\n(Struggles with small cluster)', fontweight='bold', color='orange')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Alternative algorithms for these cases:\")\n",
    "print(\"- Non-spherical: DBSCAN, Hierarchical Clustering\")\n",
    "print(\"- Unequal sizes: DBSCAN, Gaussian Mixture Models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Segmentation Example\n",
    "np.random.seed(42)\n",
    "n_customers = 300\n",
    "\n",
    "# Generate synthetic customer data\n",
    "annual_income = np.random.normal(50000, 15000, n_customers)\n",
    "spending_score = np.random.normal(50, 20, n_customers)\n",
    "\n",
    "# Create clusters (different customer segments)\n",
    "customer_data = np.column_stack([annual_income, spending_score])\n",
    "\n",
    "# Apply K-Means\n",
    "kmeans_customers = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "customer_segments = kmeans_customers.fit_predict(customer_data)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(annual_income, spending_score, alpha=0.6, s=50, c='gray')\n",
    "plt.xlabel('Annual Income ($)', fontsize=11)\n",
    "plt.ylabel('Spending Score', fontsize=11)\n",
    "plt.title('Customer Data (Unlabeled)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(annual_income, spending_score, c=customer_segments, \n",
    "           cmap='viridis', alpha=0.6, s=50)\n",
    "plt.scatter(kmeans_customers.cluster_centers_[:, 0], \n",
    "           kmeans_customers.cluster_centers_[:, 1],\n",
    "           c='red', marker='x', s=200, linewidths=3, label='Segment Centers')\n",
    "plt.xlabel('Annual Income ($)', fontsize=11)\n",
    "plt.ylabel('Spending Score', fontsize=11)\n",
    "plt.title('Customer Segmentation (5 Segments)', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Segment analysis\n",
    "print(\"Customer Segment Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "for i in range(5):\n",
    "    segment_data = customer_data[customer_segments == i]\n",
    "    print(f\"\\nSegment {i+1}:\")\n",
    "    print(f\"  Size: {len(segment_data)} customers\")\n",
    "    print(f\"  Avg Income: ${segment_data[:, 0].mean():.0f}\")\n",
    "    print(f\"  Avg Spending Score: {segment_data[:, 1].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Practice Problems\n",
    "\n",
    "### Problem 1: Find Optimal K\n",
    "\n",
    "Given a dataset, determine the optimal number of clusters using both Elbow and Silhouette methods.\n",
    "\n",
    "### Problem 2: Image Compression with K-Means\n",
    "\n",
    "Use K-Means to compress an image by reducing the number of colors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary & Key Takeaways\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **K-Means Algorithm**:\n",
    "   - Initialize centroids\n",
    "   - Assign points to nearest centroid\n",
    "   - Update centroids\n",
    "   - Repeat until convergence\n",
    "\n",
    "2. **Choosing K**:\n",
    "   - Elbow Method: Look for \"bend\" in inertia plot\n",
    "   - Silhouette Score: Higher is better (maximize)\n",
    "\n",
    "3. **When to Use**:\n",
    "   - Spherical clusters of similar size\n",
    "   - Known or estimable number of clusters\n",
    "   - Large datasets (efficient)\n",
    "\n",
    "4. **When NOT to Use**:\n",
    "   - Non-spherical clusters\n",
    "   - Unknown number of clusters (without analysis)\n",
    "   - Outliers present\n",
    "\n",
    "### Time Complexity:\n",
    "- Training: O(n × k × i × d)\n",
    "  - n = number of points\n",
    "  - k = number of clusters\n",
    "  - i = number of iterations\n",
    "  - d = number of dimensions\n",
    "- Prediction: O(k × d) per point\n",
    "\n",
    "### Next Steps:\n",
    "1. **Hierarchical Clustering**: For non-spherical clusters\n",
    "2. **DBSCAN**: For clusters of arbitrary shape and outlier detection\n",
    "3. **Gaussian Mixture Models**: For soft clustering (probabilistic)\n",
    "\n",
    "---\n",
    "\n",
    "**Resources:**\n",
    "- Scikit-learn Documentation: https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
    "- \"The Elements of Statistical Learning\" by Hastie, Tibshirani, Friedman\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
