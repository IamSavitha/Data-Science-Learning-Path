{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Guide to Gradient Descent and Optimization\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "1. What gradient descent is and why it's fundamental to ML\n",
    "2. How gradient descent works step-by-step\n",
    "3. Learning rate and its critical importance\n",
    "4. Variants: Batch, Mini-batch, and Stochastic GD\n",
    "5. Advanced optimizers: Momentum, RMSprop, Adam\n",
    "6. Convergence, local minima, and practical considerations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Gradient Descent?\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "**Gradient Descent** is an iterative optimization algorithm for finding the minimum of a function.\n",
    "\n",
    "**Intuition:** Imagine you're hiking down a mountain in thick fog. You can only see your immediate surroundings. How do you get to the bottom?\n",
    "- **Step 1:** Look around you (compute gradient)\n",
    "- **Step 2:** Take a step in the steepest downhill direction (negative gradient)\n",
    "- **Step 3:** Repeat until you reach the bottom\n",
    "\n",
    "This is exactly what gradient descent does!\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "Update rule:\n",
    "$$\\theta_{new} = \\theta_{old} - \\alpha \\nabla f(\\theta_{old})$$\n",
    "\n",
    "Where:\n",
    "- $\\theta$ = parameters we're optimizing\n",
    "- $\\alpha$ = learning rate (step size)\n",
    "- $\\nabla f$ = gradient of the loss function\n",
    "\n",
    "### Why It Matters in ML\n",
    "\n",
    "**Every ML model training uses gradient descent:**\n",
    "- Linear regression â†’ minimize MSE\n",
    "- Logistic regression â†’ minimize cross-entropy\n",
    "- Neural networks â†’ minimize loss via backpropagation\n",
    "- Deep learning â†’ all modern architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simple 1D example\n",
    "def f(x):\n",
    "    \"\"\"Simple quadratic function\"\"\"\n",
    "    return x**2 + 2*x + 1\n",
    "\n",
    "def df_dx(x):\n",
    "    \"\"\"Derivative of f\"\"\"\n",
    "    return 2*x + 2\n",
    "\n",
    "# Gradient descent implementation\n",
    "def gradient_descent_1d(start_x, learning_rate, num_iterations):\n",
    "    \"\"\"Perform gradient descent on 1D function\"\"\"\n",
    "    x = start_x\n",
    "    history = [x]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        gradient = df_dx(x)\n",
    "        x = x - learning_rate * gradient\n",
    "        history.append(x)\n",
    "    \n",
    "    return np.array(history)\n",
    "\n",
    "# Run gradient descent\n",
    "start = 5.0\n",
    "lr = 0.1\n",
    "iterations = 20\n",
    "path = gradient_descent_1d(start, lr, iterations)\n",
    "\n",
    "# Visualize\n",
    "x = np.linspace(-6, 6, 200)\n",
    "y = f(x)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Left: Function with path\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y, 'b-', linewidth=2, label='f(x) = xÂ² + 2x + 1')\n",
    "plt.plot(path, f(path), 'ro-', markersize=8, linewidth=2, label='GD path')\n",
    "plt.scatter([-1], [0], color='green', s=200, marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Minimum', zorder=5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Gradient Descent Path')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Convergence\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(path)), f(path), 'b-', linewidth=2, marker='o')\n",
    "plt.axhline(y=0, color='green', linestyle='--', linewidth=2, label='True minimum')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Convergence: Loss vs Iteration')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Starting point: x = {start}, f(x) = {f(start):.4f}\")\n",
    "print(f\"After {iterations} iterations: x = {path[-1]:.4f}, f(x) = {f(path[-1]):.4f}\")\n",
    "print(f\"True minimum: x = -1, f(x) = 0\")\n",
    "print(f\"\\nâœ“ Gradient descent successfully found the minimum!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. The Learning Rate\n",
    "\n",
    "### What is the Learning Rate?\n",
    "\n",
    "The **learning rate** $\\alpha$ controls how big our steps are.\n",
    "\n",
    "**Critical balance:**\n",
    "- **Too small** â†’ slow convergence, many iterations needed\n",
    "- **Too large** â†’ overshooting, divergence, instability\n",
    "- **Just right** â†’ fast and stable convergence âœ“\n",
    "\n",
    "This is THE most important hyperparameter in training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different learning rates\n",
    "learning_rates = [0.01, 0.1, 0.5, 1.0, 1.5]\n",
    "start = 5.0\n",
    "iterations = 30\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "x_plot = np.linspace(-8, 8, 200)\n",
    "y_plot = f(x_plot)\n",
    "\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    path = gradient_descent_1d(start, lr, iterations)\n",
    "    \n",
    "    axes[idx].plot(x_plot, y_plot, 'b-', linewidth=2, alpha=0.3)\n",
    "    axes[idx].plot(path, f(path), 'ro-', markersize=6, linewidth=2)\n",
    "    axes[idx].scatter([-1], [0], color='green', s=200, marker='*', \n",
    "                     edgecolors='black', linewidths=2, zorder=5)\n",
    "    axes[idx].set_xlabel('x')\n",
    "    axes[idx].set_ylabel('f(x)')\n",
    "    axes[idx].set_title(f'Learning Rate = {lr}')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_ylim(-2, 50)\n",
    "    \n",
    "    # Add annotation\n",
    "    final_loss = f(path[-1])\n",
    "    if lr <= 0.5:\n",
    "        status = \"âœ“ Converged\" if final_loss < 1 else \"Slow\"\n",
    "        color = 'green' if final_loss < 1 else 'orange'\n",
    "    else:\n",
    "        status = \"âœ— Diverged\" if final_loss > 10 else \"Unstable\"\n",
    "        color = 'red' if final_loss > 10 else 'orange'\n",
    "    \n",
    "    axes[idx].text(0.05, 0.95, status, transform=axes[idx].transAxes,\n",
    "                  fontsize=12, verticalalignment='top', \n",
    "                  bbox=dict(boxstyle='round', facecolor=color, alpha=0.5))\n",
    "\n",
    "# Summary plot\n",
    "axes[5].axis('off')\n",
    "summary_text = (\n",
    "    \"Learning Rate Guidelines:\\n\\n\"\n",
    "    \"Î± = 0.01: Too slow\\n\"\n",
    "    \"  â€¢ Many iterations needed\\n\"\n",
    "    \"  â€¢ Safe but inefficient\\n\\n\"\n",
    "    \"Î± = 0.1-0.5: Good! âœ“\\n\"\n",
    "    \"  â€¢ Fast convergence\\n\"\n",
    "    \"  â€¢ Stable\\n\\n\"\n",
    "    \"Î± â‰¥ 1.0: Too large\\n\"\n",
    "    \"  â€¢ Overshooting\\n\"\n",
    "    \"  â€¢ May diverge\"\n",
    ")\n",
    "axes[5].text(0.1, 0.9, summary_text, transform=axes[5].transAxes,\n",
    "            fontsize=11, verticalalignment='top', family='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== LEARNING RATE COMPARISON ===\")\n",
    "for lr in learning_rates:\n",
    "    path = gradient_descent_1d(start, lr, iterations)\n",
    "    final_loss = f(path[-1])\n",
    "    print(f\"Î± = {lr:4.2f} â†’ Final loss: {final_loss:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate in Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence speed comparison\n",
    "learning_rates = [0.01, 0.1, 0.3]\n",
    "colors = ['blue', 'green', 'red']\n",
    "labels = ['Slow (Î±=0.01)', 'Good (Î±=0.1)', 'Fast (Î±=0.3)']\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for lr, color, label in zip(learning_rates, colors, labels):\n",
    "    path = gradient_descent_1d(5.0, lr, 50)\n",
    "    plt.plot(range(len(path)), f(path), color=color, linewidth=2, \n",
    "            marker='o', markersize=3, label=label)\n",
    "\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Convergence Speed vs Learning Rate')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for lr, color, label in zip(learning_rates, colors, labels):\n",
    "    path = gradient_descent_1d(5.0, lr, 50)\n",
    "    plt.plot(path, color=color, linewidth=2, marker='o', markersize=3, label=label)\n",
    "\n",
    "plt.axhline(y=-1, color='black', linestyle='--', linewidth=1, alpha=0.5, label='True minimum')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Parameter Value (x)')\n",
    "plt.title('Parameter Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"â€¢ Smaller learning rate = slower but safer\")\n",
    "print(\"â€¢ Larger learning rate = faster but may overshoot\")\n",
    "print(\"â€¢ Log scale shows exponential convergence\")\n",
    "print(\"â€¢ In practice: start with Î± â‰ˆ 0.001-0.1, tune from there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Multivariable Gradient Descent\n",
    "\n",
    "### Extension to Multiple Dimensions\n",
    "\n",
    "For functions with multiple parameters:\n",
    "\n",
    "$$\\vec{\\theta}_{new} = \\vec{\\theta}_{old} - \\alpha \\nabla f(\\vec{\\theta}_{old})$$\n",
    "\n",
    "Where $\\nabla f$ is the gradient vector:\n",
    "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial \\theta_1} \\\\ \\frac{\\partial f}{\\partial \\theta_2} \\\\ \\vdots \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D example: f(x, y) = xÂ² + yÂ²\n",
    "def f_2d(params):\n",
    "    \"\"\"2D quadratic function\"\"\"\n",
    "    x, y = params\n",
    "    return x**2 + y**2\n",
    "\n",
    "def gradient_2d(params):\n",
    "    \"\"\"Gradient of f(x,y) = xÂ² + yÂ²\"\"\"\n",
    "    x, y = params\n",
    "    return np.array([2*x, 2*y])\n",
    "\n",
    "def gradient_descent_2d(start, learning_rate, num_iterations):\n",
    "    \"\"\"Gradient descent in 2D\"\"\"\n",
    "    params = np.array(start)\n",
    "    history = [params.copy()]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grad = gradient_2d(params)\n",
    "        params = params - learning_rate * grad\n",
    "        history.append(params.copy())\n",
    "    \n",
    "    return np.array(history)\n",
    "\n",
    "# Run gradient descent from different starting points\n",
    "start_points = [[3, 3], [-3, 2], [2, -3], [-2, -2]]\n",
    "lr = 0.1\n",
    "iterations = 20\n",
    "\n",
    "# Create mesh for contour plot\n",
    "x = np.linspace(-4, 4, 100)\n",
    "y = np.linspace(-4, 4, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "# 2D contour plot\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "contour = ax1.contour(X, Y, Z, levels=20, cmap='viridis')\n",
    "ax1.clabel(contour, inline=True, fontsize=8)\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for start, color in zip(start_points, colors):\n",
    "    path = gradient_descent_2d(start, lr, iterations)\n",
    "    ax1.plot(path[:, 0], path[:, 1], 'o-', color=color, linewidth=2, \n",
    "            markersize=6, label=f'Start: {start}')\n",
    "\n",
    "ax1.scatter([0], [0], color='yellow', s=300, marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Minimum', zorder=5)\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('2D Gradient Descent: All Paths Lead to Minimum')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# 3D surface plot\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax2.plot_surface(X, Y, Z, cmap='viridis', alpha=0.6)\n",
    "\n",
    "for start, color in zip(start_points, colors):\n",
    "    path = gradient_descent_2d(start, lr, iterations)\n",
    "    z_path = np.array([f_2d(p) for p in path])\n",
    "    ax2.plot(path[:, 0], path[:, 1], z_path, 'o-', color=color, \n",
    "            linewidth=2, markersize=4)\n",
    "\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_zlabel('f(x,y)')\n",
    "ax2.set_title('3D View: Descending the Surface')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation:\")\n",
    "print(\"â€¢ All paths converge to the global minimum (0, 0)\")\n",
    "print(\"â€¢ Paths are perpendicular to contour lines\")\n",
    "print(\"â€¢ Gradient always points toward the minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Linear Regression with Gradient Descent\n",
    "\n",
    "### Real ML Example\n",
    "\n",
    "Model: $\\hat{y} = wx + b$\n",
    "\n",
    "Loss (MSE): $L = \\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y}_i - y_i)^2$\n",
    "\n",
    "Gradients:\n",
    "$$\\frac{\\partial L}{\\partial w} = \\frac{2}{n}\\sum_{i=1}^{n}(wx_i + b - y_i) \\cdot x_i$$\n",
    "$$\\frac{\\partial L}{\\partial b} = \\frac{2}{n}\\sum_{i=1}^{n}(wx_i + b - y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X_data = np.linspace(0, 10, 100)\n",
    "y_data = 3 * X_data + 7 + np.random.randn(100) * 2  # True: y = 3x + 7 + noise\n",
    "\n",
    "def predict(X, w, b):\n",
    "    return w * X + b\n",
    "\n",
    "def mse_loss(X, y, w, b):\n",
    "    y_pred = predict(X, w, b)\n",
    "    return np.mean((y_pred - y)**2)\n",
    "\n",
    "def compute_gradients(X, y, w, b):\n",
    "    n = len(X)\n",
    "    y_pred = predict(X, w, b)\n",
    "    error = y_pred - y\n",
    "    \n",
    "    dL_dw = (2/n) * np.sum(error * X)\n",
    "    dL_db = (2/n) * np.sum(error)\n",
    "    \n",
    "    return dL_dw, dL_db\n",
    "\n",
    "def gradient_descent_linear_regression(X, y, learning_rate, num_iterations):\n",
    "    \"\"\"Train linear regression using gradient descent\"\"\"\n",
    "    # Initialize parameters\n",
    "    w = 0.0\n",
    "    b = 0.0\n",
    "    \n",
    "    history = {\n",
    "        'w': [w],\n",
    "        'b': [b],\n",
    "        'loss': [mse_loss(X, y, w, b)]\n",
    "    }\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Compute gradients\n",
    "        dL_dw, dL_db = compute_gradients(X, y, w, b)\n",
    "        \n",
    "        # Update parameters\n",
    "        w = w - learning_rate * dL_dw\n",
    "        b = b - learning_rate * dL_db\n",
    "        \n",
    "        # Record history\n",
    "        history['w'].append(w)\n",
    "        history['b'].append(b)\n",
    "        history['loss'].append(mse_loss(X, y, w, b))\n",
    "    \n",
    "    return w, b, history\n",
    "\n",
    "# Train the model\n",
    "w_final, b_final, history = gradient_descent_linear_regression(\n",
    "    X_data, y_data, learning_rate=0.01, num_iterations=100\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Data and fitted line\n",
    "axes[0, 0].scatter(X_data, y_data, alpha=0.5, label='Data')\n",
    "axes[0, 0].plot(X_data, predict(X_data, 0, 0), 'r--', linewidth=2, \n",
    "               label=f'Initial: y = 0x + 0', alpha=0.5)\n",
    "axes[0, 0].plot(X_data, predict(X_data, w_final, b_final), 'g-', linewidth=2,\n",
    "               label=f'Final: y = {w_final:.2f}x + {b_final:.2f}')\n",
    "axes[0, 0].plot(X_data, 3*X_data + 7, 'b:', linewidth=2, label='True: y = 3x + 7')\n",
    "axes[0, 0].set_xlabel('x')\n",
    "axes[0, 0].set_ylabel('y')\n",
    "axes[0, 0].set_title('Linear Regression Result')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss over time\n",
    "axes[0, 1].plot(history['loss'], 'b-', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('MSE Loss')\n",
    "axes[0, 1].set_title('Loss Decreases Over Time')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter evolution: w\n",
    "axes[1, 0].plot(history['w'], 'r-', linewidth=2)\n",
    "axes[1, 0].axhline(y=3, color='green', linestyle='--', linewidth=2, label='True value')\n",
    "axes[1, 0].set_xlabel('Iteration')\n",
    "axes[1, 0].set_ylabel('Weight (w)')\n",
    "axes[1, 0].set_title('Weight Converges to True Value')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter evolution: b\n",
    "axes[1, 1].plot(history['b'], 'b-', linewidth=2)\n",
    "axes[1, 1].axhline(y=7, color='green', linestyle='--', linewidth=2, label='True value')\n",
    "axes[1, 1].set_xlabel('Iteration')\n",
    "axes[1, 1].set_ylabel('Bias (b)')\n",
    "axes[1, 1].set_title('Bias Converges to True Value')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== TRAINING RESULTS ===\")\n",
    "print(f\"True parameters: w = 3.0, b = 7.0\")\n",
    "print(f\"Learned parameters: w = {w_final:.4f}, b = {b_final:.4f}\")\n",
    "print(f\"Initial loss: {history['loss'][0]:.4f}\")\n",
    "print(f\"Final loss: {history['loss'][-1]:.4f}\")\n",
    "print(f\"\\nâœ“ Gradient descent successfully learned the model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Variants of Gradient Descent\n",
    "\n",
    "### Three Main Types\n",
    "\n",
    "1. **Batch Gradient Descent**: Use ALL data to compute gradient\n",
    "   - Accurate but slow for large datasets\n",
    "   \n",
    "2. **Stochastic Gradient Descent (SGD)**: Use ONE sample at a time\n",
    "   - Fast but noisy updates\n",
    "   \n",
    "3. **Mini-batch Gradient Descent**: Use small batches (e.g., 32, 64 samples)\n",
    "   - Best of both worlds âœ“ (most commonly used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate larger dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "X_large = np.random.randn(n_samples)\n",
    "y_large = 2 * X_large + 1 + np.random.randn(n_samples) * 0.5\n",
    "\n",
    "def sgd_update(X, y, w, b, learning_rate):\n",
    "    \"\"\"Single SGD update using one random sample\"\"\"\n",
    "    idx = np.random.randint(len(X))\n",
    "    x_i, y_i = X[idx], y[idx]\n",
    "    \n",
    "    y_pred = w * x_i + b\n",
    "    error = y_pred - y_i\n",
    "    \n",
    "    dL_dw = 2 * error * x_i\n",
    "    dL_db = 2 * error\n",
    "    \n",
    "    w = w - learning_rate * dL_dw\n",
    "    b = b - learning_rate * dL_db\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def minibatch_update(X, y, w, b, learning_rate, batch_size):\n",
    "    \"\"\"Mini-batch update\"\"\"\n",
    "    indices = np.random.choice(len(X), batch_size, replace=False)\n",
    "    X_batch = X[indices]\n",
    "    y_batch = y[indices]\n",
    "    \n",
    "    y_pred = w * X_batch + b\n",
    "    error = y_pred - y_batch\n",
    "    \n",
    "    dL_dw = (2/batch_size) * np.sum(error * X_batch)\n",
    "    dL_db = (2/batch_size) * np.sum(error)\n",
    "    \n",
    "    w = w - learning_rate * dL_dw\n",
    "    b = b - learning_rate * dL_db\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "# Compare variants\n",
    "def compare_gd_variants(X, y, lr, iterations):\n",
    "    results = {}\n",
    "    \n",
    "    # Batch GD\n",
    "    w, b = 0.0, 0.0\n",
    "    losses_batch = []\n",
    "    for i in range(iterations):\n",
    "        dL_dw, dL_db = compute_gradients(X, y, w, b)\n",
    "        w = w - lr * dL_dw\n",
    "        b = b - lr * dL_db\n",
    "        losses_batch.append(mse_loss(X, y, w, b))\n",
    "    results['Batch GD'] = losses_batch\n",
    "    \n",
    "    # SGD\n",
    "    w, b = 0.0, 0.0\n",
    "    losses_sgd = []\n",
    "    for i in range(iterations):\n",
    "        w, b = sgd_update(X, y, w, b, lr)\n",
    "        losses_sgd.append(mse_loss(X, y, w, b))\n",
    "    results['SGD'] = losses_sgd\n",
    "    \n",
    "    # Mini-batch GD\n",
    "    w, b = 0.0, 0.0\n",
    "    losses_minibatch = []\n",
    "    for i in range(iterations):\n",
    "        w, b = minibatch_update(X, y, w, b, lr, batch_size=32)\n",
    "        losses_minibatch.append(mse_loss(X, y, w, b))\n",
    "    results['Mini-batch GD (32)'] = losses_minibatch\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison\n",
    "results = compare_gd_variants(X_large, y_large, lr=0.01, iterations=200)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for name, losses in results.items():\n",
    "    plt.plot(losses, linewidth=2, label=name, alpha=0.8)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Convergence: Batch vs SGD vs Mini-batch')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, max([max(l) for l in results.values()]) * 0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for name, losses in results.items():\n",
    "    # Use moving average for smoothing\n",
    "    window = 10\n",
    "    smoothed = np.convolve(losses, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(smoothed, linewidth=2, label=name, alpha=0.8)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE Loss (smoothed)')\n",
    "plt.title('Smoothed Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== COMPARISON ===\")\n",
    "print(\"\\nBatch GD:\")\n",
    "print(\"  âœ“ Smooth, deterministic convergence\")\n",
    "print(\"  âœ— Slow for large datasets (uses all data per update)\")\n",
    "print(\"\\nSGD:\")\n",
    "print(\"  âœ“ Fast updates (one sample at a time)\")\n",
    "print(\"  âœ— Noisy, can jump around\")\n",
    "print(\"  âœ“ Can escape local minima\")\n",
    "print(\"\\nMini-batch GD:\")\n",
    "print(\"  âœ“ Balance of speed and stability\")\n",
    "print(\"  âœ“ Efficient for GPU computation\")\n",
    "print(\"  âœ“ Most commonly used in practice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Advanced Optimizers\n",
    "\n",
    "### Beyond Vanilla Gradient Descent\n",
    "\n",
    "Modern deep learning uses enhanced versions of GD:\n",
    "\n",
    "1. **Momentum**: Add velocity term (like rolling ball)\n",
    "2. **RMSprop**: Adaptive learning rates\n",
    "3. **Adam**: Combines momentum + RMSprop (most popular!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement optimizers\n",
    "class Optimizer:\n",
    "    \"\"\"Base optimizer class\"\"\"\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.lr = learning_rate\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    \"\"\"Standard SGD\"\"\"\n",
    "    def step(self, params, grads):\n",
    "        return params - self.lr * grads\n",
    "\n",
    "class Momentum(Optimizer):\n",
    "    \"\"\"SGD with Momentum\"\"\"\n",
    "    def __init__(self, learning_rate=0.01, beta=0.9):\n",
    "        super().__init__(learning_rate)\n",
    "        self.beta = beta\n",
    "        self.velocity = None\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        if self.velocity is None:\n",
    "            self.velocity = np.zeros_like(params)\n",
    "        \n",
    "        self.velocity = self.beta * self.velocity + (1 - self.beta) * grads\n",
    "        return params - self.lr * self.velocity\n",
    "\n",
    "class RMSprop(Optimizer):\n",
    "    \"\"\"RMSprop optimizer\"\"\"\n",
    "    def __init__(self, learning_rate=0.01, beta=0.9, epsilon=1e-8):\n",
    "        super().__init__(learning_rate)\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        self.squared_grads = None\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        if self.squared_grads is None:\n",
    "            self.squared_grads = np.zeros_like(params)\n",
    "        \n",
    "        self.squared_grads = self.beta * self.squared_grads + (1 - self.beta) * grads**2\n",
    "        return params - self.lr * grads / (np.sqrt(self.squared_grads) + self.epsilon)\n",
    "\n",
    "class Adam(Optimizer):\n",
    "    \"\"\"Adam optimizer (Adaptive Moment Estimation)\"\"\"\n",
    "    def __init__(self, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        super().__init__(learning_rate)\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = None  # First moment (momentum)\n",
    "        self.v = None  # Second moment (RMSprop)\n",
    "        self.t = 0\n",
    "    \n",
    "    def step(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m = np.zeros_like(params)\n",
    "            self.v = np.zeros_like(params)\n",
    "        \n",
    "        self.t += 1\n",
    "        \n",
    "        # Update moments\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * grads\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * grads**2\n",
    "        \n",
    "        # Bias correction\n",
    "        m_hat = self.m / (1 - self.beta1**self.t)\n",
    "        v_hat = self.v / (1 - self.beta2**self.t)\n",
    "        \n",
    "        return params - self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "\n",
    "# Test on challenging function (Rosenbrock)\n",
    "def rosenbrock(params):\n",
    "    x, y = params\n",
    "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
    "\n",
    "def rosenbrock_grad(params):\n",
    "    x, y = params\n",
    "    dx = -2 * (1 - x) - 400 * x * (y - x**2)\n",
    "    dy = 200 * (y - x**2)\n",
    "    return np.array([dx, dy])\n",
    "\n",
    "def optimize(optimizer, start, num_iterations):\n",
    "    params = np.array(start)\n",
    "    history = [params.copy()]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads = rosenbrock_grad(params)\n",
    "        params = optimizer.step(params, grads)\n",
    "        history.append(params.copy())\n",
    "    \n",
    "    return np.array(history)\n",
    "\n",
    "# Compare optimizers\n",
    "start_point = [-1.5, 2.5]\n",
    "iterations = 500\n",
    "lr = 0.001\n",
    "\n",
    "optimizers = {\n",
    "    'SGD': SGD(lr),\n",
    "    'Momentum': Momentum(lr, beta=0.9),\n",
    "    'RMSprop': RMSprop(lr * 10, beta=0.9),  # Higher LR for RMSprop\n",
    "    'Adam': Adam(lr * 10, beta1=0.9, beta2=0.999)\n",
    "}\n",
    "\n",
    "paths = {}\n",
    "for name, opt in optimizers.items():\n",
    "    paths[name] = optimize(opt, start_point, iterations)\n",
    "\n",
    "# Visualize\n",
    "x = np.linspace(-2, 2, 100)\n",
    "y = np.linspace(-1, 3, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = (1 - X)**2 + 100 * (Y - X**2)**2\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Contour plot with paths\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.contour(X, Y, Z, levels=np.logspace(-1, 3, 20), cmap='viridis')\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "for (name, path), color in zip(paths.items(), colors):\n",
    "    plt.plot(path[:, 0], path[:, 1], '-', color=color, linewidth=2, \n",
    "            label=name, alpha=0.7)\n",
    "plt.scatter([1], [1], color='yellow', s=300, marker='*', \n",
    "           edgecolors='black', linewidths=2, label='Minimum', zorder=5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Optimization Paths (Rosenbrock Function)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss over time\n",
    "plt.subplot(2, 2, 2)\n",
    "for name, path in paths.items():\n",
    "    losses = [rosenbrock(p) for p in path]\n",
    "    plt.plot(losses, linewidth=2, label=name)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Convergence Speed')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Distance to minimum\n",
    "plt.subplot(2, 2, 3)\n",
    "for name, path in paths.items():\n",
    "    distances = np.linalg.norm(path - np.array([1, 1]), axis=1)\n",
    "    plt.plot(distances, linewidth=2, label=name)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Distance to Minimum')\n",
    "plt.title('Distance from Optimal Point')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Final comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "final_losses = [rosenbrock(paths[name][-1]) for name in optimizers.keys()]\n",
    "plt.bar(optimizers.keys(), final_losses, color=colors)\n",
    "plt.ylabel('Final Loss')\n",
    "plt.title('Final Loss Comparison')\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== OPTIMIZER COMPARISON ===\")\n",
    "for name in optimizers.keys():\n",
    "    final_loss = rosenbrock(paths[name][-1])\n",
    "    print(f\"{name:10s}: Final loss = {final_loss:.6f}\")\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "print(\"â€¢ Adam usually converges fastest (combines best of both worlds)\")\n",
    "print(\"â€¢ Momentum helps with oscillations\")\n",
    "print(\"â€¢ RMSprop adapts learning rate per parameter\")\n",
    "print(\"â€¢ In practice: Start with Adam, learning_rate â‰ˆ 0.001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Practical Considerations\n",
    "\n",
    "### Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PRACTICAL TIPS ===\")\n",
    "print(\"\\n1. LEARNING RATE:\")\n",
    "print(\"   â€¢ Start: 0.001 - 0.01\")\n",
    "print(\"   â€¢ Too high â†’ divergence, NaN\")\n",
    "print(\"   â€¢ Too low â†’ slow training\")\n",
    "print(\"   â€¢ Solution: Learning rate schedule (decay over time)\")\n",
    "\n",
    "print(\"\\n2. FEATURE SCALING:\")\n",
    "print(\"   â€¢ Always normalize features (mean=0, std=1)\")\n",
    "print(\"   â€¢ Prevents different scales from dominating\")\n",
    "print(\"   â€¢ Makes optimization landscape more spherical\")\n",
    "\n",
    "print(\"\\n3. INITIALIZATION:\")\n",
    "print(\"   â€¢ Don't initialize all weights to zero!\")\n",
    "print(\"   â€¢ Use small random values\")\n",
    "print(\"   â€¢ Xavier/He initialization for deep networks\")\n",
    "\n",
    "print(\"\\n4. CONVERGENCE:\")\n",
    "print(\"   â€¢ Monitor loss over time\")\n",
    "print(\"   â€¢ Stop when loss plateaus (early stopping)\")\n",
    "print(\"   â€¢ Watch for oscillations (reduce learning rate)\")\n",
    "\n",
    "print(\"\\n5. OPTIMIZER CHOICE:\")\n",
    "print(\"   â€¢ Default: Adam (learning_rate=0.001)\")\n",
    "print(\"   â€¢ For RNNs: Sometimes SGD with momentum\")\n",
    "print(\"   â€¢ For fine-tuning: Lower learning rate\")\n",
    "\n",
    "print(\"\\n6. DEBUGGING:\")\n",
    "print(\"   â€¢ Loss increasing â†’ learning rate too high\")\n",
    "print(\"   â€¢ Loss not decreasing â†’ learning rate too low or bad initialization\")\n",
    "print(\"   â€¢ Loss = NaN â†’ numerical instability, reduce LR\")\n",
    "print(\"   â€¢ Slow convergence â†’ try different optimizer or increase LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different LR schedules\n",
    "def constant_lr(epoch, initial_lr):\n",
    "    return initial_lr\n",
    "\n",
    "def step_decay(epoch, initial_lr, drop_rate=0.5, epochs_drop=10):\n",
    "    return initial_lr * (drop_rate ** (epoch // epochs_drop))\n",
    "\n",
    "def exponential_decay(epoch, initial_lr, decay_rate=0.95):\n",
    "    return initial_lr * (decay_rate ** epoch)\n",
    "\n",
    "def cosine_annealing(epoch, initial_lr, total_epochs):\n",
    "    return initial_lr * 0.5 * (1 + np.cos(np.pi * epoch / total_epochs))\n",
    "\n",
    "# Visualize schedules\n",
    "epochs = np.arange(0, 100)\n",
    "initial_lr = 0.1\n",
    "\n",
    "schedules = {\n",
    "    'Constant': [constant_lr(e, initial_lr) for e in epochs],\n",
    "    'Step Decay': [step_decay(e, initial_lr) for e in epochs],\n",
    "    'Exponential': [exponential_decay(e, initial_lr) for e in epochs],\n",
    "    'Cosine Annealing': [cosine_annealing(e, initial_lr, 100) for e in epochs]\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for name, lrs in schedules.items():\n",
    "    plt.plot(epochs, lrs, linewidth=2, label=name)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedules')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "print(\"Why use LR schedules?\")\n",
    "print(\"â€¢ Start high: Make quick progress early\")\n",
    "print(\"â€¢ Decay over time: Fine-tune as we approach minimum\")\n",
    "print(\"â€¢ Helps convergence and final performance\")\n",
    "print(\"\\nMost common: Exponential decay or step decay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement Gradient Descent\n",
    "Implement gradient descent for $f(x) = x^3 - 3x^2 + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 - Your code here\n",
    "def f(x):\n",
    "    return x**3 - 3*x**2 + 2\n",
    "\n",
    "def df_dx(x):\n",
    "    # YOUR CODE: compute derivative\n",
    "    pass\n",
    "\n",
    "# YOUR CODE: implement gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Logistic Regression\n",
    "Implement gradient descent for logistic regression on the iris dataset (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - Your code here\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data[:100, :2]  # First two features, first two classes\n",
    "y = iris.target[:100]\n",
    "\n",
    "# YOUR CODE: implement logistic regression with gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Compare Learning Rates\n",
    "Test learning rates [0.001, 0.01, 0.1, 0.5] and plot convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 - Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Implement Adam\n",
    "Implement the Adam optimizer from scratch and test on a simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 - Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SOLUTIONS ===\")\n",
    "\n",
    "# Exercise 1\n",
    "print(\"\\nExercise 1: f(x) = xÂ³ - 3xÂ² + 2\")\n",
    "print(\"f'(x) = 3xÂ² - 6x\")\n",
    "print(\"(See implementation in Section 1)\")\n",
    "\n",
    "# Exercise 2\n",
    "print(\"\\nExercise 2: Logistic Regression\")\n",
    "print(\"Gradients: âˆ‚L/âˆ‚w = (1/n)Î£(p-y)Â·x\")\n",
    "print(\"           âˆ‚L/âˆ‚b = (1/n)Î£(p-y)\")\n",
    "print(\"(See implementation in derivatives notebook)\")\n",
    "\n",
    "# Exercise 3\n",
    "print(\"\\nExercise 3: Learning Rate Comparison\")\n",
    "print(\"(See Section 2 for detailed comparison)\")\n",
    "\n",
    "# Exercise 4\n",
    "print(\"\\nExercise 4: Adam Optimizer\")\n",
    "print(\"(See Section 6 for full implementation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Key Takeaways\n",
    "\n",
    "### Core Concepts:\n",
    "1. âœ… **Gradient descent** = iterative optimization following negative gradient\n",
    "2. âœ… **Learning rate** = controls step size (most important hyperparameter)\n",
    "3. âœ… **Variants**: Batch, Mini-batch (best), Stochastic\n",
    "4. âœ… **Advanced**: Momentum, RMSprop, Adam (use Adam by default)\n",
    "\n",
    "### Update Rule:\n",
    "$$\\theta_{new} = \\theta_{old} - \\alpha \\nabla f(\\theta_{old})$$\n",
    "\n",
    "### Practical Guidelines:\n",
    "- **Start with Adam**, learning_rate = 0.001\n",
    "- **Normalize features** before training\n",
    "- **Use mini-batches** (32-256 samples)\n",
    "- **Monitor loss** for convergence\n",
    "- **Learning rate schedule** for better convergence\n",
    "\n",
    "### When to Use What:\n",
    "- **Simple problems**: Batch GD\n",
    "- **Large datasets**: Mini-batch GD with Adam\n",
    "- **Fine-tuning**: Lower learning rate (0.0001)\n",
    "- **RNNs**: Sometimes SGD with momentum\n",
    "\n",
    "### Debugging Tips:\n",
    "- Loss increasing â†’ LR too high\n",
    "- Loss flat â†’ LR too low or stuck\n",
    "- Loss = NaN â†’ Numerical instability\n",
    "- Slow convergence â†’ Try different optimizer\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You understand gradient descent! ðŸŽ‰**\n",
    "\n",
    "**Next: Chain Rule and Backpropagation - how neural networks compute these gradients!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
